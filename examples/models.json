[
  {
    "name": "llama-2-7b",
    "num_parameters": 7.0,
    "num_layers": 32,
    "hidden_size": 4096,
    "num_attention_heads": 32,
    "vocab_size": 32000,
    "max_sequence_length": 4096
  },
  {
    "name": "llama-2-13b",
    "num_parameters": 13.0,
    "num_layers": 40,
    "hidden_size": 5120,
    "num_attention_heads": 40,
    "vocab_size": 32000,
    "max_sequence_length": 4096
  },
  {
    "name": "llama-2-70b",
    "num_parameters": 70.0,
    "num_layers": 80,
    "hidden_size": 8192,
    "num_attention_heads": 64,
    "num_kv_heads": 8,
    "vocab_size": 32000,
    "max_sequence_length": 4096
  },
  {
    "name": "mistral-7b",
    "num_parameters": 7.3,
    "num_layers": 32,
    "hidden_size": 4096,
    "num_attention_heads": 32,
    "num_kv_heads": 8,
    "vocab_size": 32000,
    "max_sequence_length": 8192
  }
]
